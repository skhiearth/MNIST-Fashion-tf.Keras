{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P7mUJVqcINSM"
   },
   "source": [
    "# Fashion MNIST Classification using tf.Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "1UbK0Uq7GWaO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: tensorflow_datasets in /Users/skhiearth/anaconda3/lib/python3.7/site-packages (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: termcolor in /Users/skhiearth/anaconda3/lib/python3.7/site-packages (from tensorflow_datasets) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: absl-py in /Users/skhiearth/anaconda3/lib/python3.7/site-packages (from tensorflow_datasets) (0.8.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy in /Users/skhiearth/anaconda3/lib/python3.7/site-packages (from tensorflow_datasets) (1.17.2)\n",
      "Requirement already satisfied, skipping upgrade: attrs in /Users/skhiearth/anaconda3/lib/python3.7/site-packages (from tensorflow_datasets) (19.3.0)\n",
      "Requirement already satisfied, skipping upgrade: promise in /Users/skhiearth/anaconda3/lib/python3.7/site-packages (from tensorflow_datasets) (2.2.1)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /Users/skhiearth/anaconda3/lib/python3.7/site-packages (from tensorflow_datasets) (3.10.0)\n",
      "Requirement already satisfied, skipping upgrade: wrapt in /Users/skhiearth/anaconda3/lib/python3.7/site-packages (from tensorflow_datasets) (1.11.2)\n",
      "Requirement already satisfied, skipping upgrade: future in /Users/skhiearth/anaconda3/lib/python3.7/site-packages (from tensorflow_datasets) (0.17.1)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-metadata in /Users/skhiearth/anaconda3/lib/python3.7/site-packages (from tensorflow_datasets) (0.15.0)\n",
      "Requirement already satisfied, skipping upgrade: dill in /Users/skhiearth/anaconda3/lib/python3.7/site-packages (from tensorflow_datasets) (0.3.1.1)\n",
      "Requirement already satisfied, skipping upgrade: requests>=2.19.0 in /Users/skhiearth/anaconda3/lib/python3.7/site-packages (from tensorflow_datasets) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: six in /Users/skhiearth/anaconda3/lib/python3.7/site-packages (from tensorflow_datasets) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: tqdm in /Users/skhiearth/anaconda3/lib/python3.7/site-packages (from tensorflow_datasets) (4.36.1)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /Users/skhiearth/anaconda3/lib/python3.7/site-packages (from protobuf>=3.6.1->tensorflow_datasets) (41.6.0.post20191030)\n",
      "Requirement already satisfied, skipping upgrade: googleapis-common-protos in /Users/skhiearth/anaconda3/lib/python3.7/site-packages (from tensorflow-metadata->tensorflow_datasets) (1.6.0)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/skhiearth/anaconda3/lib/python3.7/site-packages (from requests>=2.19.0->tensorflow_datasets) (1.24.2)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /Users/skhiearth/anaconda3/lib/python3.7/site-packages (from requests>=2.19.0->tensorflow_datasets) (2019.9.11)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /Users/skhiearth/anaconda3/lib/python3.7/site-packages (from requests>=2.19.0->tensorflow_datasets) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /Users/skhiearth/anaconda3/lib/python3.7/site-packages (from requests>=2.19.0->tensorflow_datasets) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TensorFlow and TF Datasets\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "tfds.disable_progress_bar()\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "logger = tf.get_logger()\n",
    "logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yR0EdgrLCaWR"
   },
   "source": [
    "## Import the Fashion MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DLdCchMdCaWQ"
   },
   "source": [
    "We use the [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist) dataset, which contains 70,000 grayscale images in 10 categories. The images show individual articles of clothing at low resolution (28 $\\times$ 28 pixels).\n",
    "\n",
    "We will use 60,000 images to train the network and 10,000 images to evaluate how accurately the network learned to classify images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7MqDQO0KCaWS"
   },
   "outputs": [],
   "source": [
    "dataset, metadata = tfds.load('fashion_mnist', as_supervised=True, with_info=True)\n",
    "train_dataset, test_dataset = dataset['train'], dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "IjnLH5S2CaWx"
   },
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', \n",
    "               'Trouser', \n",
    "               'Pullover', \n",
    "               'Dress', \n",
    "               'Coat',\n",
    "               'Sandal',      \n",
    "               'Shirt',   \n",
    "               'Sneaker',  \n",
    "               'Bag',   \n",
    "               'Ankle boot']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ES6uQoLKCaWr"
   },
   "source": [
    "## Preprocess the data\n",
    "\n",
    "The value of each pixel in the image data is an integer in the range `[0,255]`. For the model to work properly, these values need to be normalized to the range `[0,1]`. So here we create a normalization function, and then apply it to each image in the test and train datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "nAsH3Zm-76pB"
   },
   "outputs": [],
   "source": [
    "num_train_examples = metadata.splits['train'].num_examples\n",
    "num_test_examples = metadata.splits['test'].num_examples\n",
    "print(\"Number of training examples: {}\".format(num_train_examples))\n",
    "print(\"Number of test examples:     {}\".format(num_test_examples))\n",
    "\n",
    "def normalize(images, labels):\n",
    "  images = tf.cast(images, tf.float32)\n",
    "  images /= 255\n",
    "  return images, labels\n",
    "\n",
    "train_dataset =  train_dataset.map(normalize)\n",
    "test_dataset  =  test_dataset.map(normalize)\n",
    "\n",
    "# Caching images in memory makes training faster.\n",
    "train_dataset =  train_dataset.cache()\n",
    "test_dataset  =  test_dataset.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "oSzE9l7PjHx0"
   },
   "outputs": [],
   "source": [
    "for image, label in test_dataset.take(1):\n",
    "  break\n",
    "image = image.numpy().reshape((28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "59veuiEZCaW4"
   },
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "9ODch-OFCaW4"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10,  activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gut8A_7rCaW6"
   },
   "source": [
    "This network has three layers:\n",
    "\n",
    "* **input** `tf.keras.layers.Flatten` — This layer transforms the images from a 2d-array of 28 $\\times$ 28 pixels, to a 1d-array of 784 pixels (28\\*28). Think of this layer as unstacking rows of pixels in the image and lining them up. This layer has no parameters to learn, as it only reformats the data.\n",
    "\n",
    "* **\"hidden\"** `tf.keras.layers.Dense`— A densely connected layer of 128 neurons. Each neuron (or node) takes input from all 784 nodes in the previous layer, weighting that input according to hidden parameters which will be learned during training, and outputs a single value to the next layer.\n",
    "\n",
    "* **output** `tf.keras.layers.Dense` — A 10-node *softmax* layer, with each node representing a class of clothing. As in the previous layer, each node takes input from the 128 nodes in the layer before it. Each node weights the input according to learned parameters, and then outputs a value in the range `[0, 1]`, representing the probability that the image belongs to that class. The sum of all 10 node values is 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qKF6uW-BCaW-"
   },
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "o_Dp8971McQ1"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "train_dataset = train_dataset.repeat().shuffle(num_train_examples).batch(BATCH_SIZE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "xvwvpA64CaW_"
   },
   "outputs": [],
   "source": [
    "model.fit(train_dataset, \n",
    "          epochs=25, \n",
    "          steps_per_epoch=math.ceil(num_train_examples/BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oEw4bZgGCaXB"
   },
   "source": [
    "## Evaluate accuracy\n",
    "\n",
    "Next, compare how the model performs on the test dataset. Use all examples we have in the test dataset to assess accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "VflXLEeECaXC"
   },
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_dataset, steps=math.ceil(num_test_examples/32))\n",
    "print('Accuracy on test dataset:', test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yWfgsmVXCaXG"
   },
   "source": [
    "As it turns out, the accuracy on the test dataset is smaller than the accuracy on the training dataset. This is completely normal, since the model was trained on the `train_dataset`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xsoS7CPDCaXH"
   },
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Ccoz4conNCpl"
   },
   "outputs": [],
   "source": [
    "for test_images, test_labels in test_dataset.take(1):\n",
    "  test_images = test_images.numpy()\n",
    "  test_labels = test_labels.numpy()\n",
    "  predictions = model.predict(test_images)\n",
    "\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "DvYmmrpIy6Y1"
   },
   "outputs": [],
   "source": [
    "def plot_image(i, predictions_array, true_labels, images):\n",
    "  predictions_array, true_label, img = predictions_array[i], true_labels[i], images[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "  \n",
    "  plt.imshow(img[...,0], cmap=plt.cm.binary)\n",
    "\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "  if predicted_label == true_label:\n",
    "    color = 'blue'\n",
    "  else:\n",
    "    color = 'red'\n",
    "  \n",
    "  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                100*np.max(predictions_array),\n",
    "                                class_names[true_label]),\n",
    "                                color=color)\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "  predictions_array, true_label = predictions_array[i], true_label[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "  thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
    "  plt.ylim([0, 1]) \n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "  \n",
    "  thisplot[predicted_label].set_color('red')\n",
    "  thisplot[true_label].set_color('blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d4Ov9OFDMmOD"
   },
   "source": [
    "Let's look at the 0th image, predictions, and prediction array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "HV5jw-5HwSmO"
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "plot_image(i, predictions, test_labels, test_images)\n",
    "plt.subplot(1,2,2)\n",
    "plot_value_array(i, predictions, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Ko-uzOufSCSe"
   },
   "outputs": [],
   "source": [
    "i = 12\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "plot_image(i, predictions, test_labels, test_images)\n",
    "plt.subplot(1,2,2)\n",
    "plot_value_array(i, predictions, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kgdvGD52CaXR"
   },
   "source": [
    "Correct prediction labels are blue and incorrect prediction labels are red. The number gives the percent (out of 100) for the predicted label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "hQlnbqaw2Qu_"
   },
   "outputs": [],
   "source": [
    "# Color correct predictions in blue, incorrect predictions in red\n",
    "num_rows = 5\n",
    "num_cols = 3\n",
    "num_images = num_rows*num_cols\n",
    "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "for i in range(num_images):\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "  plot_image(i, predictions, test_labels, test_images)\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "  plot_value_array(i, predictions, test_labels)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Classifying Images of Clothing",
   "private_outputs": true,
   "provenance": [
    {
     "file_id": "1RtaPMyNP4oBZO399FwZhDTViIKcn4ejn",
     "timestamp": 1551740419056
    },
    {
     "file_id": "1KyYXwI-97lUmVfZKZ8SxsN6UYJtaEfqL",
     "timestamp": 1550693255203
    },
    {
     "file_id": "15RAhUsxUkt6zsrxgvkcAvhclaPuFJGKd",
     "timestamp": 1550685714406
    },
    {
     "file_id": "https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/basic_classification.ipynb",
     "timestamp": 1549491628070
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
